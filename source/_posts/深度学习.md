---
title: 深度学习
date: 2021-03-22 14:34
katex: true
tags:
- 主干网络
- 论文
categories:
- 实验室
---

## 主干网络对比

评估数据

1、**top-1错误**：如果模型预测的置信度最高的类与真正的类不相同，则会发生top-1错误。

2、**top-5错误**：当真正的类不在模型预测置信度最高的前5个类中时，会发生前top-5错误（按置信度排序）。

![Accuracy Comparison of Models](https://imgconvert.csdnimg.cn/aHR0cHM6Ly93d3cubGVhcm5vcGVuY3YuY29tL3dwLWNvbnRlbnQvdXBsb2Fkcy8yMDE5LzA2L0FjY3VyYWN5LUNvbXBhcmlzb24tb2YtTW9kZWxzLnBuZw?x-oss-process=image/format,png)

3、**CPU的推断时间**：推断时间是模型推理过程所花费的时间。

4、**GPU的推断时间** : 当推理运行于gpu时，所花费的推理时间。

![Inference time on CPU comparison](https://imgconvert.csdnimg.cn/aHR0cHM6Ly93d3cubGVhcm5vcGVuY3YuY29tL3dwLWNvbnRlbnQvdXBsb2Fkcy8yMDE5LzA2L01vZGVsLUluZmVyZW5jZS1UaW1lLUNvbXBhcmlzb24tb24tQ1BVLW1zLUxvd2VyLWlzLWJldHRlci0ucG5n?x-oss-process=image/format,png)

![Inference time on GPU comparison](https://imgconvert.csdnimg.cn/aHR0cHM6Ly93d3cubGVhcm5vcGVuY3YuY29tL3dwLWNvbnRlbnQvdXBsb2Fkcy8yMDE5LzA2L01vZGVsLUluZmVyZW5jZS1UaW1lLUNvbXBhcmlzb24tb24tR1BVLW1zLUxvd2VyLWlzLWJldHRlci0ucG5n?x-oss-process=image/format,png)

5、**模型大小**：这里的大小代表由PyTorch提供的预训练模型的.pth（或.pt) 文件所占用的物理空间。

![Model size comparison](https://imgconvert.csdnimg.cn/aHR0cHM6Ly93d3cubGVhcm5vcGVuY3YuY29tL3dwLWNvbnRlbnQvdXBsb2Fkcy8yMDE5LzA2L01vZGVsLVNpemUtQ29tcGFyaXNvbi5wbmc?x-oss-process=image/format,png)一个好的模型将具有低的TOP-1错误，低的TOP-5错误，低的CPU和GPU上的推理时间和低的模型大小。 所有的实验都是在同一个输入图像上进行的，并且多次进行，这样就可以将特定模型的所有结果的平均值进行分析。

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly93d3cubGVhcm5vcGVuY3YuY29tL3dwLWNvbnRlbnQvdXBsb2Fkcy8yMDE5LzA2L1ByZS1UcmFpbmVkLU1vZGVsLUNvbXBhcmlzb24ucG5n?x-oss-process=image/format,png)

CIFAR-10上Resnet18对比，超参数设置如下

| EPOCH | BATCH_SIZE | LEARNING_RATE |
| ----- | ---------- | ------------- |
| 135   | 128        | 0.01          |

EPOCH=103，best_acc= 92.190%

EPOCH=102，best_acc= 91.950%

EPOCH=132,best_acc= 92.430%（改进算法分类）

基于机器视觉的模块化输电网的异物检测300~500

**Datasets**:[Oxford Flowers-102][1],102类，Size (train/test)：Size (train/test)

| Network         | TOP-1 acc% | TOP-5 acc% | [FLOPs][2] | Params.    |
| --------------- | ---------- | --------- | ---------- | ---------- |
| Resnet-50       |            |            |           | 23,705,252 |
| Efficientnet-b0 |            |            |           | 5,288,548  |
| Rexnet-1.0x     |            |            |           | 4,796,873  |

> [**模型复杂度**][3]
>
> 描述一个具体的深度学习模型，除了性能指标（分类任务的准确度、检测任务的mAP等），还需要考虑该模型的复杂度，即参数(Parameters，使用Mb作为单位)的个数和（前向推理的）计算量（使用FLOPs（FLoating point OPerations）或MAC(Memory Access Cost)衡量）。
>
> 前者描述了这个复杂的网络到底需要多少参数才能定义它，即存储该模型所需的存储空间。后者描述了数据过一遍这么复杂的网络需要多大的计算量呢，即使用该模型时所需的计算力。



对于一个卷积层，假设其大小为$h×w×c×n$（其中c为#input channel, n为#output channel），输出的feature map尺寸为$H'×W'$，则该卷积层的

$\#paras = n×（h×w×c+1）$

$ \#FLOPs = H'×W'×N(H×W×C+1)，即FLOPs=H'×W'×\#paras $

### Benchmark

#### [torchvision](https://pytorch.org/docs/1.0.0/torchvision/models.html)

| Model         | Input Resolution | Params(M) | MACs(G) | Top-1 error | Top-5 error |
| ------------- | ---------------- | --------- | ------- | ----------- | ----------- |
| alexnet       | 224x224          | 61.1      | 0.72    | 43.45       | 20.91       |
| vgg11         | 224x224          | 132.86    | 7.63    | 30.98       | 11.37       |
| vgg13         | 224x224          | 133.05    | 11.34   | 30.07       | 10.75       |
| vgg16         | 224x224          | 138.36    | 15.5    | 28.41       | 9.62        |
| vgg19         | 224x224          | 143.67    | 19.67   | 27.62       | 9.12        |
| vgg11_bn      | 224x224          | 132.87    | 7.64    | 29.62       | 10.19       |
| vgg13_bn      | 224x224          | 133.05    | 11.36   | 28.45       | 9.63        |
| vgg16_bn      | 224x224          | 138.37    | 15.53   | 26.63       | 8.50        |
| vgg19_bn      | 224x224          | 143.68    | 19.7    | 25.76       | 8.15        |
| resnet18      | 224x224          | 11.69     | 1.82    | 30.24       | 10.92       |
| resnet34      | 224x224          | 21.8      | 3.68    | 26.70       | 8.58        |
| resnet50      | 224x224          | 25.56     | 4.12    | 23.85       | 7.13        |
| resnet101     | 224x224          | 44.55     | 7.85    | 22.63       | 6.44        |
| resnet152     | 224x224          | 60.19     | 11.58   | 21.69       | 5.94        |
| squeezenet1_0 | 224x224          | 1.25      | 0.83    | 41.90       | 19.58       |
| squeezenet1_1 | 224x224          | 1.24      | 0.36    | 41.81       | 19.38       |
| densenet121   | 224x224          | 7.98      | 2.88    | 25.35       | 7.83        |
| densenet169   | 224x224          | 14.15     | 3.42    | 24.00       | 7.00        |
| densenet201   | 224x224          | 20.01     | 4.37    | 22.80       | 6.43        |
| densenet161   | 224x224          | 28.68     | 7.82    | 22.35       | 6.20        |
| inception_v3  | 224x224          | 27.16     | 2.85    | 22.55       | 6.44        |

- Top-1 error - ImageNet single-crop top-1 error (224x224)
- Top-5 error - ImageNet single-crop top-5 error (224x224)

#### [Cadene/pretrained-models.pytorch](https://github.com/Cadene/pretrained-models.pytorch)

| Model               | Input Resolution | Params(M) | MACs(G) | Acc@1  | Acc@5  |
| ------------------- | ---------------- | --------- | ------- | ------ | ------ |
| alexnet             | 224x224          | 61.1      | 0.72    | 56.432 | 79.194 |
| bninception         | 224x224          | 11.3      | 2.05    | 73.524 | 91.562 |
| cafferesnet101      | 224x224          | 44.55     | 7.62    | 76.2   | 92.766 |
| densenet121         | 224x224          | 7.98      | 2.88    | 74.646 | 92.136 |
| densenet161         | 224x224          | 28.68     | 7.82    | 77.56  | 93.798 |
| densenet169         | 224x224          | 14.15     | 3.42    | 76.026 | 92.992 |
| densenet201         | 224x224          | 20.01     | 4.37    | 77.152 | 93.548 |
| dpn107              | 224x224          | 86.92     | 18.42   | 79.746 | 94.684 |
| dpn131              | 224x224          | 79.25     | 16.13   | 79.432 | 94.574 |
| dpn68               | 224x224          | 12.61     | 2.36    | 75.868 | 92.774 |
| dpn68b              | 224x224          | 12.61     | 2.36    | 77.034 | 93.59  |
| dpn92               | 224x224          | 37.67     | 6.56    | 79.4   | 94.62  |
| dpn98               | 224x224          | 61.57     | 11.76   | 79.224 | 94.488 |
| fbresnet152         | 224x224          | 60.27     | 11.6    | 77.386 | 93.594 |
| inceptionresnetv2   | 299x299          | 55.84     | 13.22   | 80.17  | 95.234 |
| inceptionv3         | 299x299          | 27.16     | 5.73    | 77.294 | 93.454 |
| inceptionv4         | 299x299          | 42.68     | 12.31   | 80.062 | 94.926 |
| nasnetalarge        | 331x331          | 88.75     | 24.04   | 82.566 | 96.086 |
| nasnetamobile       | 224x224          | 5.29      | 0.59    | 74.08  | 91.74  |
| pnasnet5large       | 331x331          | 86.06     | 25.21   | 82.736 | 95.992 |
| polynet             | 331x331          | 95.37     | 34.9    | 81.002 | 95.624 |
| resnet101           | 224x224          | 44.55     | 7.85    | 77.438 | 93.672 |
| resnet152           | 224x224          | 60.19     | 11.58   | 78.428 | 94.11  |
| resnet18            | 224x224          | 11.69     | 1.82    | 70.142 | 89.274 |
| resnet34            | 224x224          | 21.8      | 3.68    | 73.554 | 91.456 |
| resnet50            | 224x224          | 25.56     | 4.12    | 76.002 | 92.98  |
| resnext101_32x4d    | 224x224          | 44.18     | 8.03    | 78.188 | 93.886 |
| resnext101_64x4d    | 224x224          | 83.46     | 15.55   | 78.956 | 94.252 |
| se_resnet101        | 224x224          | 49.33     | 7.63    | 78.396 | 94.258 |
| se_resnet152        | 224x224          | 66.82     | 11.37   | 78.658 | 94.374 |
| se_resnet50         | 224x224          | 28.09     | 3.9     | 77.636 | 93.752 |
| se_resnext101_32x4d | 224x224          | 48.96     | 8.05    | 80.236 | 95.028 |
| se_resnext50_32x4d  | 224x224          | 27.56     | 4.28    | 79.076 | 94.434 |
| senet154            | 224x224          | 115.09    | 20.82   | 81.304 | 95.498 |
| squeezenet1_0       | 224x224          | 1.25      | 0.83    | 58.108 | 80.428 |
| squeezenet1_1       | 224x224          | 1.24      | 0.36    | 58.25  | 80.8   |
| vgg11               | 224x224          | 132.86    | 7.63    | 68.97  | 88.746 |
| vgg11_bn            | 224x224          | 132.87    | 7.64    | 70.452 | 89.818 |
| vgg13               | 224x224          | 133.05    | 11.34   | 69.662 | 89.264 |
| vgg13_bn            | 224x224          | 133.05    | 11.36   | 71.508 | 90.494 |
| vgg16               | 224x224          | 138.36    | 15.5    | 71.636 | 90.354 |
| vgg16_bn            | 224x224          | 138.37    | 15.53   | 73.518 | 91.608 |
| vgg19               | 224x224          | 143.67    | 19.67   | 72.08  | 90.822 |
| vgg19_bn            | 224x224          | 143.68    | 19.7    | 74.266 | 92.066 |
| xception            | 299x299          | 22.86     | 8.42    | 78.888 | 94.292 |

- Acc@1 - ImageNet single-crop top-1 accuracy on validation images of the same size used during the training process.
- Acc@5 - ImageNet single-crop top-5 accuracy on validation images of the same size used during the training process.

### 消融实验

## 胶囊学习

https://easyai.tech/ai-definition/capsule/

## 图像超分辨

> 应用：模糊视频的实时处理

https://github.com/subeeshvasu/Awesome-Deblurring

### 图像质量评估

https://www.cnblogs.com/vincent2012/archive/2012/10/13/2723152.html

- PSNR，即峰值信噪比

$PSNR=10\times\log(\frac {{255}^2} {MSE})$

  - MSE：均方误差
  - I^n：原始图像的第n个像素值
  - P^n：处理后图像的第n个像素值
  - Framesize：像素长*像素宽

### 端到端学习

https://cloud.tencent.com/developer/article/1647850

#### [USRNet](https://github.com/cszn/USRNet)

https://blog.csdn.net/qq_37614597/article/details/114786923

https://inf.news/zh-hans/technique/556625fbf1051cb48fbb97013b66ae9b.html

https://github.com/geopi1/Improved_USRNet

## 可视化工具

### 模型结构可视化

Tensorboard

### Pytorch训练过程可视化

 Visdom可视化

### CNN训练图片可视化

【教学使用——了解卷积内部操作过程】https://poloclub.github.io/cnn-explainer/

[taishan1994/pytorch-cnn-visualizations: Pytorch implementation of convolutional neural network visualization techniques (github.com)](https://github.com/taishan1994/pytorch-cnn-visualizations)

[1]:M.-E. Nilsback and A. Zisserman. Automated flower classification over a large number of classes. In 2008 Sixth Indian Conference on Computer Vision, Graphics & Image Processing, pages 722–729. IEEE, 2008, [Visual Geometry Group - University of Oxford](https://www.robots.ox.ac.uk/~vgg/data/flowers/102/) 
[2]:FLOPS：floating point operations per second的缩写，意指每秒浮点运算次数，理解为计算速度。是一个衡量硬件性能的指标。

[3]:CNN模型复杂度（FLOPs、MAC）、参数量与运行速度_张鹏的博客-CSDN博客(https://blog.csdn.net/weixin_39833897/article/details/105807172)